library(quanteda)
tw <- corpus(users$description[users$description!=""])
dfm <- dfm(tw, remove=c(stopwords("english"), stopwords("spanish"),
"t.co", "https", "rt", "rts", "http"),
remove_punct=TRUE)
# create wordcloud
par(mar=c(0,0,0,0))
textplot_wordcloud(dfm, rot.per=0, scale=c(3, .50), max.words=100)
users <- searchUsers(q="cologne political science", count=100, oauth_folder="../credentials")
users <- searchUsers(q="cologne political science", count=100, oauth_folder="../credentials")
users <- searchUsers(q="political science", count=100, oauth_folder="../credentials")
str(users)
users$screen_name[1:10]
getStatuses(ids=c("474134260149157888", "266038556504494082"), filename="old-tweets.json",
oauth_folder="../credentials")
parseTweets("old-tweets.json")
fb_oauth = 'EAACEdEose0cBAKsf0F6y6MN1MyFUVD1bOQasjzwY046ZAWPQsQ359xlG64jX3LcveTNjm68EOSZAHrLh3EiAODnwZC6lEKnNnDyHAyGYddplhabyZA6K7JO9Glys6gN45NnYySYO4lGy5bJhbdW01jx3FxRAO8udNzoNqOidp2U9TkwteXAGuEG2I6q22q0ZD'
library(Rfacebook)
fb_oauth = 'EAACEdEose0cBAKsf0F6y6MN1MyFUVD1bOQasjzwY046ZAWPQsQ359xlG64jX3LcveTNjm68EOSZAHrLh3EiAODnwZC6lEKnNnDyHAyGYddplhabyZA6K7JO9Glys6gN45NnYySYO4lGy5bJhbdW01jx3FxRAO8udNzoNqOidp2U9TkwteXAGuEG2I6q22q0ZD'
getUsers("me", token=fb_oauth, private_info=TRUE)
page <- getPage("DonaldTrump", token=fb_oauth, n=20, reactions=TRUE, api="v2.9")
page[1,]
page[which.max(page$likes_count),]
page <- getPage("104544669596569", token=fb_oauth, n=100, reactions=TRUE, api="v2.9")
page[which.max(page$likes_count),]
page[which.max(page$comments_count),]
page[which.max(page$shares_count),]
page <- getPage("barackobama", token=fb_oauth, n=100,
since='2012/11/01', until='2012/11/10')
page[which.max(page$likes_count),]
post_id <- page$id[which.max(page$likes_count)]
post <- getPost(post_id, token=fb_oauth, n.comments=1000, likes=FALSE)
comments <- post$comments
head(comments)
comments[which.max(comments$likes_count),]
group <- getGroup("150048245063649", token=fb_oauth, n=50)
str(group)
?getGroup
library(quanteda)
tweets <- read.csv('../data/candidate-tweets.csv', stringsAsFactors=F)
# loading lexicon of positive and negative words (from Neal Caren)
lexicon <- read.csv("../data/lexicon.csv", stringsAsFactors=F)
pos.words <- lexicon$word[lexicon$polarity=="positive"]
neg.words <- lexicon$word[lexicon$polarity=="negative"]
# a look at a random sample of positive and negative words
sample(pos.words, 10)
sample(neg.words, 10)
library(streamR)
?filterStream
my_oauth <- list(consumer_key = "r5QoWg8hk5rYaz2Zio3EUhdkL",
consumer_secret = "FcET1BZG1CrQPMydonoITxSl2v7fCuxNp3BO1ZEE6lDOhmFC6f",
access_token="4515151-ZCfCmgFmuk0vXnUCCpyPcJh0TmpBa3BWKijtiXBkZq",
access_token_secret = "UCh6O0spvSxNSnGK0PkI4aNBAMKgCSqBLmYUdH7cfVgGI")
)
my_oauth <- list(consumer_key = "r5QoWg8hk5rYaz2Zio3EUhdkL",
consumer_secret = "FcET1BZG1CrQPMydonoITxSl2v7fCuxNp3BO1ZEE6lDOhmFC6f",
access_token="4515151-ZCfCmgFmuk0vXnUCCpyPcJh0TmpBa3BWKijtiXBkZq",
access_token_secret = "UCh6O0spvSxNSnGK0PkI4aNBAMKgCSqBLmYUdH7cfVgGI")
my_oauth <- list(consumer_key = "r5QoWg8hk5rYaz2Zio3EUhdkL",
consumer_secret = "FcET1BZG1CrQPMydonoITxSl2v7fCuxNp3BO1ZEE6lDOhmFC6f",
access_token="4515151-ZCfCmgFmuk0vXnUCCpyPcJh0TmpBa3BWKijtiXBkZq",
access_token_secret = "UCh6O0spvSxNSnGK0PkI4aNBAMKgCSqBLmYUdH7cfVgGI")
save(my_oauth, file="~/my_oauth")
library(tweetscores)
getUsers(screen_names="LSEnews", oauth = my_oauth)
getUsers(screen_names="LSEnews", oauth = my_oauth)[[1]]$screen_name
load("~/my_oauth")
library(tweetscores)
getUsers(screen_names="LSEnews", oauth = my_oauth)[[1]]$screen_name
library(streamR)
filterStream(file.name="../data/trump-tweets.json", track="trump",
timeout=20, oauth=my_oauth)
length(grep("bieber", tweets$text, ignore.case=TRUE))
tweets <- parseTweets("../data/trump-tweets.json")
tweets[1,]
load("~/my_oauth")
library(tweetscores)
library(streamR)
searchTweets(q=c("doug jones", "roy moore"),
filename="../data/alabama-tweets.json",
n=1000, until="2017-12-15",
oauth=my_oauth)
searchTweets(q=c("#TrumpShutdown", "#SchumerShutdown"),
filename="../data/shutdown-tweets.json",
n=1000, until="2017-01-22",
oauth=my_oauth)
searchTweets(q=c("#TrumpShutdown", "#SchumerShutdown"),
filename="../data/shutdown-tweets.json",
n=1000, until="2018-01-22",
oauth=my_oauth)
tweets <- parseTweets("../data/shutdown-tweets.json")
tweets <- parseTweets("../data/shutdown-tweets.json", legacy=TRUE)
str(tweets)
tweets = "../data/shutdown-tweets.json"
results <- stream_in(tweets)
results$retweeted_status.retweet_count
retweet_count <- ifelse(!is.na(results$retweeted_status.retweet_count),
results$retweeted_status.retweet_count, results$retweet_count)
str(retweet_count)
length(results$text)
str(results$text)
retweet_count <- rep(NA, length(results$text))
if (!is.null(results$retweeted_status.retweet_count)){
retweet_count <- ifelse(!is.na(results$retweeted_status.retweet_count),
results$retweeted_status.retweet_count, results$retweet_count)
}
favorite_count <- rep(NA, length(results$text))
if (!is.null(results$retweeted_status.favorite_count)){
favorite_count <- ifelse(!is.na(results$retweeted_status.favorite_count),
results$retweeted_status.favorite_count, results$favorite_count)
}
df <- data.frame(
text = results$text,
retweet_count = retweet_count,
favorite_count = favorite_count,
favorited = results$favorited,
truncated = results$truncated,
id_str = results$id_str,
in_reply_to_screen_name = results$in_reply_to_screen_name,
source = results$source,
retweeted = results$retweeted,
created_at = results$created_at,
in_reply_to_status_id_str = results$in_reply_to_status_id_str,
in_reply_to_user_id_str = results$in_reply_to_user_id_str,
lang = results$lang,
listed_count = results$user.listed_count,
verified = results$user.verified,
location = results$user.location,
user_id_str = results$user.id_str,
description = results$user.description,
geo_enabled = results$user.geo_enabled,
user_created_at = results$user.created_at,
statuses_count = results$user.statuses_count,
followers_count = results$user.followers_count,
favourites_count = results$user.favourites_count,
protected = results$user.protected,
user_url = results$user.url,
name = results$user.name,
time_zone = results$user.time_zone,
user_lang = results$user.lang,
utc_offset = results$user.utc_offset,
friends_count = results$user.friends_count,
screen_name = results$user.screen_name,
stringsAsFactors=F)
favorite_count
results$favorited
results$truncated
results$id_str
results$in_reply_to_screen_name
results$source
results$retweeted
results$retweeted.0
results$created_at
results$in_reply_to_status_id_str
results$in_reply_to_user_id_str
results$lang
results$user.listed_count
results$user.verified
results$user.location
results$user.id_str
results$user.description
results$user.geo_enabled
results$user.created_at
df <- data.frame(
text = results$text,
retweet_count = retweet_count,
favorite_count = favorite_count,
favorited = results$favorited,
truncated = results$truncated,
id_str = results$id_str,
in_reply_to_screen_name = results$in_reply_to_screen_name,
source = results$source,
retweeted = results$retweeted.0, ##
created_at = results$created_at,
in_reply_to_status_id_str = results$in_reply_to_status_id_str,
in_reply_to_user_id_str = results$in_reply_to_user_id_str,
lang = results$lang,
listed_count = results$user.listed_count,
verified = results$user.verified,
location = results$user.location,
user_id_str = results$user.id_str,
description = results$user.description,
geo_enabled = results$user.geo_enabled,
user_created_at = results$user.created_at,
statuses_count = results$user.statuses_count,
followers_count = results$user.followers_count,
favourites_count = results$user.favourites_count,
protected = results$user.protected,
user_url = results$user.url,
name = results$user.name,
time_zone = results$user.time_zone,
user_lang = results$user.lang,
utc_offset = results$user.utc_offset,
friends_count = results$user.friends_count,
screen_name = results$user.screen_name,
stringsAsFactors=F)
results[, names(results)grep("retweeted", names(results))]
results[, names(results)[grep("retweeted", names(results))]]
names(results)[grep("retweeted", names(results))]
names(results)[grep("retweeted", names(results))][1]
grep("retweeted", names(results))[1]
results[,grep("retweeted", names(results))[1]]
results[grep("retweeted", names(results))[1]]
results[[grep("retweeted", names(results))[1]]]
load("~/my_oauth")
library(tweetscores)
library(streamR)
tweets <- parseTweets("../data/shutdown-tweets.json")
library(stringr)
ht <- str_extract_all(tweets$text, "#(\\d|\\w)+")
ht <- unlist(ht)
head(sort(table(ht), decreasing = TRUE))
?str_extract_all
wh <- c("realDonaldTrump", "POTUS", "VP", "FLOTUS")
users <- getUsersBatch(screen_names=wh,
oauth=my_oauth)
str(users)
users[which.max(users$followers_count),]
users$screen_name[which.max(users$followers_count)]
getTimeline(filename="../data/realDonaldTrump.json", screen_name="realDonaldTrump",
n=1000, oauth=my_oauth)
my_oauth
load("~/my_oauth")
library(tweetscores)
library(streamR)
getTimeline(filename="../data/realDonaldTrump.json", screen_name="realDonaldTrump", n=1000, oauth=my_oauth)
filename="../data/realDonaldTrump.json"
screen_name="realDonaldTrump"
n=1000
oauth=my_oauth
oauth
getOAuth <- function(x, verbose=TRUE){
# first check if x is an object
if (class(x)=="list"){
my_oauth <- ROAuth::OAuthFactory$new(consumerKey=x$consumer_key,
consumerSecret=x$consumer_secret,
oauthKey=x$access_token,
oauthSecret=x$access_token_secret,
needsVerifier=FALSE,
handshakeComplete=TRUE,
verifier="1",
requestURL="https://api.twitter.com/oauth/request_token",
authURL="https://api.twitter.com/oauth/authorize",
accessURL="https://api.twitter.com/oauth/access_token",
signMethod="HMAC")
}
# first check if x exists in disk
if (class(x)!="list" && file.exists(x)){
info <- file.info(x)
# if it's a folder, load one and return
if (info$isdir){
creds <- list.files(x, full.names=TRUE)
cr <- sample(creds, 1)
if (verbose){message(cr)}
load(cr)
}
# if not, check type
if (!info$isdir){
# if it's not csv, guess it's Rdata and load it
if (!grepl("csv", x)){
if (verbose){message(x)}
load(x)
}
# if it's a csv file read it, and create token
if (grepl("csv", x)){
d <- read.csv(x, stringsAsFactors=F)
creds <- d[sample(1:nrow(d),1),]
my_oauth <- ROAuth::OAuthFactory$new(consumerKey=creds$consumer_key,
consumerSecret=creds$consumer_secret,
oauthKey=creds$access_token,
oauthSecret=creds$access_token_secret,
needsVerifier=FALSE,
handshakeComplete=TRUE,
verifier="1",
requestURL="https://api.twitter.com/oauth/request_token",
authURL="https://api.twitter.com/oauth/authorize",
accessURL="https://api.twitter.com/oauth/access_token",
signMethod="HMAC")
# testing that it works
#url = "https://api.twitter.com/1.1/users/show.json"
#params = list(screen_name = "twitter")
#my_oauth$OAuthRequest(URL=url, params=params, method="GET",
#                     cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
}
}
}
return(my_oauth)
}
getLimitFriends <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "friends,application")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(jsonlite::fromJSON(response)$resources$friends$`/friends/ids`['remaining']))
}
getLimitRate <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "followers,application")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(jsonlite::fromJSON(response)$resources$application$`/application/rate_limit_status`[['remaining']]))
}
getLimitFollowers <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "followers,application")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(jsonlite::fromJSON(response)$resources$followers$`/followers/ids`[['remaining']]))
}
getLimitUsers <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "users,application")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(jsonlite::fromJSON(response)$resources$users$`/users/lookup`[['remaining']]))
}
getLimitSearch <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "search")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(rjson::fromJSON(response)$resources$search$`/search/tweets`[['remaining']]))
}
getLimitList <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "lists,application")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(rjson::fromJSON(response)$resources$lists$`/lists/members`['remaining']))
}
getLimitSearch <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "search")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(rjson::fromJSON(response)$resources$search$`/search/tweets`[['remaining']]))
}
getLimitRetweets <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "statuses,application")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(rjson::fromJSON(response)$resources$statuses$`/statuses/retweeters/ids`[['remaining']]))
}
getLimitStatuses <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "statuses,application")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(rjson::fromJSON(response)$resources$statuses$`/statuses/lookup`[['remaining']]))
}
getLimitTimeline <- function(my_oauth){
url <- "https://api.twitter.com/1.1/application/rate_limit_status.json"
params <- list(resources = "statuses,application")
response <- my_oauth$OAuthRequest(URL=url, params=params, method="GET",
cainfo=system.file("CurlSSL", "cacert.pem", package = "RCurl"))
return(unlist(rjson::fromJSON(response)$resources$statuses$`/statuses/user_timeline`[['remaining']]))
}
my_oauth <- getOAuth(oauth, verbose=verbose)
limit <- getLimitTimeline(my_oauth)
if (verbose) message(limit, " hits left")
verbose = TRUE
if (verbose) message(limit, " hits left")
limit
url <- "https://api.twitter.com/1.1/statuses/user_timeline.json"
id = NULL
since_id = NULL
if (!is.null(screen_name)){
params <- list(screen_name = screen_name, count=200, trim_user=trim_user)
}
if (!is.null(id)){
params <- list(id=id, count=200, trim_user=trim_user)
}
if (!is.null(since_id)){
params[["since_id"]] <- since_id
}
query <- lapply(params, function(x) URLencode(as.character(x)))
screen_name
params
is.null(screen_name)
trim_user = FALSE
trim_user="true"
sleep=.5
## first API call
if (!is.null(screen_name)){
params <- list(screen_name = screen_name, count=200, trim_user=trim_user)
}
if (!is.null(id)){
params <- list(id=id, count=200, trim_user=trim_user)
}
if (!is.null(since_id)){
params[["since_id"]] <- since_id
}
query <- lapply(params, function(x) URLencode(as.character(x)))
query
# preparing OAuth token for httr
options("httr_oauth_cache"=FALSE)
app <- httr::oauth_app("twitter", key = my_oauth$consumerKey,
secret = my_oauth$consumerSecret)
credentials <- list(oauth_token = my_oauth$oauthKey, oauth_token_secret = my_oauth$oauthSecret)
twitter_token <- httr::Token1.0$new(endpoint = NULL, params = list(as_header = TRUE),
app = app, credentials = credentials)
# first query
url.data <- httr::GET(url, query = query, httr::config(token = twitter_token))
limit <- limit - 1
## changing oauth token if we hit the limit
if (verbose) message(limit, " hits left")
cr_old <- my_oauth
limit
my_oauth != cr_old
my_oauth
cr_old
as.list(my_oauth)
(as.list(my_oauth) != as.list(cr_old))
all.equal(my_oauth, cr_old)
library(tweetscores)
getTimeline(filename="../data/realDonaldTrump.json", screen_name="realDonaldTrump", n=1000, oauth=my_oauth)
load("~/my_oauth")
library(tweetscores)
library(streamR)
getTimeline(filename="../data/realDonaldTrump.json", screen_name="realDonaldTrump", n=1000, oauth=my_oauth)
tweets <- parseTweets("../data/realDonaldTrump.json")
ht <- str_extract_all(tweets$text, "#(\\d|\\w)+")
ht <- unlist(ht)
head(sort(table(ht), decreasing = TRUE))
getTimeline(filename="../data/realDonaldTrump.json", screen_name="realDonaldTrump", n=1000, oauth=my_oauth, trim_user="false")
tweets <- parseTweets("../data/realDonaldTrump.json")
followers <- getFollowers("MethodologyLSE",
oauth=my_oauth)
friends <- getFriends("MethodologyLSE",
oauth=my_oauth)
users <- getUsersBatch(ids=friends, oauth=my_oauth)
library(quanteda)
tw <- corpus(users$description[users$description!=""])
dfm <- dfm(tw, remove=c(stopwords("english"), stopwords("spanish"),
"t.co", "https", "rt", "rts", "http"),
remove_punct=TRUE)
topfeatures(dfm)
topfeatures(dfm, n = 30)
par(mar=c(0,0,0,0))
textplot_wordcloud(dfm, rot.per=0, scale=c(3, .50), max.words=100)
textplot_wordcloud(dfm, rot.per=0, scale=c(2, .25), max.words=100)
textplot_wordcloud(dfm, rot.per=0, scale=c(2.5, .25), max.words=100)
textplot_wordcloud(dfm, rot.per=0, scale=c(2.5, .50), max.words=100)
textplot_wordcloud(dfm, rot.per=0, scale=c(2.5, .25), max.words=100)
users <- searchUsers(q="london school of economics", count=100, oauth=my_oauth)
users$screen_name[1:10]
getStatuses(ids=c("474134260149157888", "266038556504494082"),
filename="../data/old-tweets.json",
oauth=my_oauth)
parseTweets("../data/old-tweets.json")
MCs <- getList(list_name="new-members-of-congress",
screen_name="cspan", oauth=my_oauth)
head(MCs)
rts <- getRetweets(id='942123433873281024', oauth=my_oauth)
users <- getUsersBatch(ids=rts, oauth=my_oauth)
library(quanteda)
tw <- corpus(users$description[users$description!=""])
dfm <- dfm(tw, remove=c(stopwords("english"), stopwords("spanish"),
"t.co", "https", "rt", "rts", "http"),
remove_punct = TRUE)
topfeatures(dfm)
par(mar=c(0,0,0,0))
textplot_wordcloud(dfm, rot.per=0, scale=c(5, .50), max.words=100)
par(mar=c(0,0,0,0))
textplot_wordcloud(dfm, rot.per=0, scale=c(5, .50), max.words=100)
textplot_wordcloud(dfm, rot.per=0, scale=c(3, .50), max.words=100)
tweets <- parseTweets("../data/realDonaldTrump.json")
tweets$date <- formatTwDate(tweets$created_at, format="date")
hist(tweets$date, breaks="month")
tweets <- parseTweets("../data/tweets_geo.json")
library(maps)
tweets$lat <- ifelse(is.na(tweets$lat), tweets$place_lat, tweets$lat)
tweets$lat
tweets$lon <- ifelse(is.na(tweets$lon), tweets$place_lon, tweets$lon)
tweets$lon
states <- map.where("state", tweets$lon, tweets$lat)
?map.where
tweets <- tweets[!is.na(tweets$lat)]
states <- map.where("state", tweets$lon, tweets$lat)
str(tweets)
tweets <- parseTweets("../data/tweets_geo.json")
library(maps)
tweets$lat <- ifelse(is.na(tweets$lat), tweets$place_lat, tweets$lat)
tweets$lon <- ifelse(is.na(tweets$lon), tweets$place_lon, tweets$lon)
tweets <- tweets[!is.na(tweets$lat),]
states <- map.where("state", tweets$lon, tweets$lat)
head(sort(table(states), decreasing=TRUE))
load("~/my_oauth")
library(tweetscores)
library(streamR)
?getTimeline
load("~/my_oauth")
library(tweetscores)
library(streamR)
getTimeline(filename="../data/realDonaldTrump.json", screen_name="realDonaldTrump", n=1000, oauth=my_oauth)
tweets <- parseTweets("../data/realDonaldTrump.json")
ht <- str_extract_all(tweets$text, "#(\\d|\\w)+")
ht <- unlist(ht)
head(sort(table(ht), decreasing = TRUE))
library(stringr)
ht <- str_extract_all(tweets$text, "#(\\d|\\w)+")
ht <- unlist(ht)
head(sort(table(ht), decreasing = TRUE))
friends <- getFriends("p_barbera", oauth=my_oauth)
user <- "p_barbera"
results <- estimateIdeology(user, friends)
summary(results)
tracePlot(results, "theta")
plot(results)
?estimateIdeology
results <- estimateIdeology(user, friends, verbose=FALSE)
